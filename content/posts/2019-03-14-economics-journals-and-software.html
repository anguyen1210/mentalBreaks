---
title: Economics journals and software preferences
author: Anthony Nguyen
date: '2019-03-22'
slug: economics-journals-and-software
categories:
tags:
  - r
  - stata
  - academia
  - economics
lastmod: '2019-03-14T20:32:13+01:00'
layout: post
type: post
highlight: tango
output:
  blogdown::html_page:
      toc: TRUE

---


<div id="TOC">
<ul>
<li><a href="#overview-of-the-database">Overview of the database</a></li>
<li><a href="#software-preferences">Software preferences</a><ul>
<li><a href="#what-is-the-most-popular-analytical-package">What is the most popular analytical package?</a></li>
<li><a href="#how-has-the-use-of-different-analytical-software-changed-over-time">How has the use of different analytical software changed over time?</a></li>
<li><a href="#software-package-tendencies-by-journal">Software package tendencies by journal</a></li>
</ul></li>
<li><a href="#and-the-textual-data">And the textual data?</a></li>
</ul>
</div>

<p>As part of my Applied Econometrics course this semester, we have lab time each week where we’re working in Stata. As it’s been made clear to us, Stata still dominates all other statistical analysis packages in the field of Economics, and it’s important to learn it, not only for it’s relative ease of use, but also, to be able to better communicate with other Economists.</p>
<p>Anyway, for our thesis work, we’ve been told that we’re free to use whatever software we would like. I’ve been chewing on this topic for a couple of weeks now, as I’ve spent a lot of time over the past two years trying to learn R. Should I go ahead and write my thesis using Stata? Does that imply learning and writing with LaTeX as a separate application instead of doing everything in Rmarkdown? Is it worth investing time to learn <a href="https://data.princeton.edu/stata/markdown">Markstat</a>? Is it really worth the extra effort to calculate robust standard errors or generate dummy variables in R?</p>
<p>With all of that said, I was very excited to see this post, ‘<a href="http://skranz.github.io/r/2019/02/21/FindingEconomicArticles.html">Finding Economic Articles with Data</a>’, from Sebastian Kranz on the <a href="https://www.r-bloggers.com/">R-bloggers</a> mailing list the other week.</p>
<p>Because the <a href="https://www.aeaweb.org/journals/">AEA</a> requires all authors to upload their data and replication code to go along with journal submissions, there’s a nice little repository of articles, data and code that goes back a little over a decade. Kranz has built a nice little Shiny <a href="http://econ.mathematik.uni-ulm.de:3200/ejd/">app that allows you to search the AEA data archives</a> to see what data is available. Definitely have a look, it’s well done.</p>
<div id="overview-of-the-database" class="section level2">
<h2>Overview of the database</h2>
<p>Using the data provided in the blog post, I thought it would be fun to run the analysis myself to see if there is any additional insight we can mine from what’s been submitted to AEA.</p>
<p>Follow the link to download the <a href="http://econ.mathematik.uni-ulm.de/ejd/articles.zip">database of economic articles</a> used by Kranz’s Shiny app.</p>
<p>Here is a quick summary of the data of interest:</p>
<table>
<thead>
<tr class="header">
<th align="right">n_articles</th>
<th align="right">pct_w_code</th>
<th align="right">yr_min</th>
<th align="right">yr_max</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">6786</td>
<td align="right">0.505</td>
<td align="right">2005</td>
<td align="right">2019</td>
</tr>
</tbody>
</table>
<p>The database provided contains information related to published articles submitted to different economic journals over a 15 year span, from 2005 until the present (March 2019 at the time of writing). Among those articles, 51% include code snippets, which we can use to analyze software package preferences.</p>
<p>Consult the app for a <a href="http://econ.mathematik.uni-ulm.de:3200/ejd/">list of journal abbreviations</a> covered in the database.</p>
<p>When we plot the number of submssions by journal, we can see that the <em>American Economic Review</em> contains the bulk of papers in this database at the present.
<img src="/posts/2019-03-14-economics-journals-and-software_files/figure-html/Plot%20number%20of%20articles%20by%20journal-1.png" width="672" /></p>
</div>
<div id="software-preferences" class="section level2">
<h2>Software preferences</h2>
<p>In the original Kranz blog post, he does a quick analysis to show what share of all code submitted to the various AER journals is written in what language. His results confirm that Stata does, in fact, dominate all other software (70% share, compared to 23% for Matlab and only 2.8% for R). After quickly peeking at the data, I can see that there are a few other popular languages in there that were not factored into his analysis, which we will factor into our analysis here.</p>
<div id="what-is-the-most-popular-analytical-package" class="section level3">
<h3>What is the most popular analytical package?</h3>
<p>Using the file extension data from the included code snippets, we can easily match these to specific software packages to see what the most popular analytical packages are among all of the journal articles in this database.</p>
<p>Here’s what the top 15 results look like:</p>
<table>
<thead>
<tr class="header">
<th align="left">file_type</th>
<th align="right">count</th>
<th align="right">share</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">do</td>
<td align="right">2741</td>
<td align="right">59.44</td>
</tr>
<tr class="even">
<td align="left">m</td>
<td align="right">947</td>
<td align="right">20.54</td>
</tr>
<tr class="odd">
<td align="left">ado</td>
<td align="right">212</td>
<td align="right">4.60</td>
</tr>
<tr class="even">
<td align="left">sas</td>
<td align="right">174</td>
<td align="right">3.77</td>
</tr>
<tr class="odd">
<td align="left">r</td>
<td align="right">123</td>
<td align="right">2.67</td>
</tr>
<tr class="even">
<td align="left">mod</td>
<td align="right">82</td>
<td align="right">1.78</td>
</tr>
<tr class="odd">
<td align="left">prg</td>
<td align="right">60</td>
<td align="right">1.30</td>
</tr>
<tr class="even">
<td align="left">ztt</td>
<td align="right">49</td>
<td align="right">1.06</td>
</tr>
<tr class="odd">
<td align="left">nb</td>
<td align="right">46</td>
<td align="right">1.00</td>
</tr>
<tr class="even">
<td align="left">c</td>
<td align="right">44</td>
<td align="right">0.95</td>
</tr>
<tr class="odd">
<td align="left">py</td>
<td align="right">39</td>
<td align="right">0.85</td>
</tr>
<tr class="even">
<td align="left">cpp</td>
<td align="right">23</td>
<td align="right">0.50</td>
</tr>
<tr class="odd">
<td align="left">f90</td>
<td align="right">22</td>
<td align="right">0.48</td>
</tr>
<tr class="even">
<td align="left">g</td>
<td align="right">20</td>
<td align="right">0.43</td>
</tr>
<tr class="odd">
<td align="left">java</td>
<td align="right">7</td>
<td align="right">0.15</td>
</tr>
</tbody>
</table>
<p>The results we have here are slightly different from what Kranz showed on his blog. One consideration where I took a different approach is choosing what denominator to scale over. As some studies include multiple code snippets in different languages, simply using the number of individual studies as the denominator (i.e. <code>length(unique(filed$id))</code>) would result in our percentages summing to greater than 1. Instead, I’ve chosen to use the total number of <code>file_type</code> entries that remained after filtering the data, which lets our <code>file_type</code> share percentages sum nicely.</p>
<p>I’ve left all of the different file types in for this first summary table, but regardless, we can see that Stata is indeed dominant (In fact, we can throw out the .ado files–a Stata format–as they are always coupled with .do files for any journal article in question).</p>
<p>Among the other top languages that show up here, we can see that SAS is still in the top five, and C and Python are both more or less in the top ten. The other file extensions are either below 1%, or come from software packages that seem to be quite niche (i.e. I don’t recognize them), so we’ll drop them for the rest of our analysis.</p>
<p>Re-running our table from above with the additional filters, we have:</p>
<table>
<thead>
<tr class="header">
<th align="left">file_type</th>
<th align="right">count</th>
<th align="right">share</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">do</td>
<td align="right">2741</td>
<td align="right">67.38</td>
</tr>
<tr class="even">
<td align="left">m</td>
<td align="right">947</td>
<td align="right">23.28</td>
</tr>
<tr class="odd">
<td align="left">sas</td>
<td align="right">174</td>
<td align="right">4.28</td>
</tr>
<tr class="even">
<td align="left">r</td>
<td align="right">123</td>
<td align="right">3.02</td>
</tr>
<tr class="odd">
<td align="left">c</td>
<td align="right">44</td>
<td align="right">1.08</td>
</tr>
<tr class="even">
<td align="left">py</td>
<td align="right">39</td>
<td align="right">0.96</td>
</tr>
</tbody>
</table>
<p>Again, we see that Stata dominates code submissions with a 67.4% share, followed by a very large share for Matlab at 23.3%. And while the data science community has made R and Python their languages of choice, we can see that among economists, they are still a minority. The aggregate figures show that SAS still has an edge over R, and even C has an edge over Python.</p>
</div>
<div id="how-has-the-use-of-different-analytical-software-changed-over-time" class="section level3">
<h3>How has the use of different analytical software changed over time?</h3>
<p>Next we can have have a look to see how the choice of code has evolved over the years:</p>
<p><img src="/posts/2019-03-14-economics-journals-and-software_files/figure-html/plot%20code%20shares%20over%20time-1.png" width="672" /></p>
<p>Looking at the use of different packages over time, the picture changes a bit. In this plot we can clearly see Stata’s consistent dominance in the economics field, remaining stable around 70% throughout all years despite the movement of the other software packages. Matlab is the next most popular software package, and its usage is also fairly stable–with maybe a slight tailing off in the past decade.</p>
<p>Among the rest, it’s interesting to see that SAS and C usage has really dropped off over the past 14 years, while conversely, R and Python have had comparable increases in usage. What the aggregate figures from before don’t show is that, by roughly 2015, R has overtaken SAS as the third most popular software package, and that, by 2018, both R and Python are more popular than either SAS or C.</p>
<p>While the plot clearly shows that both R and Python users are still a minority in the Economics field at the moment (6.7% and 4.8% shares in 2019 respectively), I’m curious to see if their upward trend will continue and if they will get closer to Matlab and Stata at any point in the future. For a number of reasons, I suspect that R and Python usage will only continue to increase going forward, though the question of how close they will get to Stata and Matlab I’m less sure of. I can’t imagine that Matlab will be able to maintain its current share going forward, but we’ll see.</p>
</div>
<div id="software-package-tendencies-by-journal" class="section level3">
<h3>Software package tendencies by journal</h3>
<p>The last thing I wanted to look at here is the relation between the different journals and coding preferences. In aggregate, we can calculate the shares of our main languages per journal and plot them as follows:
<img src="/posts/2019-03-14-economics-journals-and-software_files/figure-html/plot%20code%20share%20by%20journal-1.png" width="672" /></p>
<p>Looking at the plot, a few things stand out to me: first, it appears that the distribution of Stata/Matlab dominance is certainly not even across all journals. The five journals on the right have quite large shares of the Matlab submissions–in particular, <em>Econometrica</em> (51%) and <em>AEJ Macroeconomics</em> (48.2%), where Matlab submissions are actually greater than Stata.</p>
<p>From the R perspective, it’s interesting to note that <em>Econometrica</em> and the <em>Journal of Economic Perspectives</em> both have over 10% of their submissions in R, making them the two leading journals for R users.</p>
<p>Lastly, we can see that the three journals on the left-hand side–<em>Journal of the Association of Environmental and Resource Economists</em>, <em>Quarterly Journal of Economics</em>, and the <em>Journal of Political Economy</em>–are notable in that they do not have any R or Python submissions at all.</p>
</div>
</div>
<div id="and-the-textual-data" class="section level2">
<h2>And the textual data?</h2>
<p>In addition to the information about code and data submitted to the journals, the dataset also includes all of the journal article titles and abstracts, which potentially allows us to derive some insight about the topics covered by the journals. My initial attempts at doing some text analysis using <a href="https://www.tidytextmining.com/">TF-IDF and LDA techniques</a> didn’t reveal very much, but given how curated the journals are, not finding any interesting patterns in the term and topic frequency patterns here is not so surprising in retrospect. I’m not sure if there’s any interesting insight buried in here somewhere, but a harder re-think of the research question is definitely required. For the moment, I’ll have to leave that for a part two of this post.</p>
</div>
